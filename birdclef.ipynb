{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.nn import init\n",
    "import torchaudio\n",
    "from torchaudio import transforms\n",
    "\n",
    "from ignite.engine import Events, create_supervised_evaluator, create_supervised_trainer\n",
    "from ignite.metrics import Accuracy, Loss, RunningAverage\n",
    "from ignite.handlers.param_scheduler import LRScheduler\n",
    "from ignite.contrib.handlers.tqdm_logger import ProgressBar\n",
    "# from ignite.contrib.metrics import ROC_AUC\n",
    "\n",
    "plt.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 1 Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"data/train_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14852 entries, 0 to 14851\n",
      "Data columns (total 13 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   primary_label     14852 non-null  object \n",
      " 1   secondary_labels  14852 non-null  object \n",
      " 2   type              14852 non-null  object \n",
      " 3   latitude          14852 non-null  float64\n",
      " 4   longitude         14852 non-null  float64\n",
      " 5   scientific_name   14852 non-null  object \n",
      " 6   common_name       14852 non-null  object \n",
      " 7   author            14852 non-null  object \n",
      " 8   license           14852 non-null  object \n",
      " 9   rating            14852 non-null  float64\n",
      " 10  time              14852 non-null  object \n",
      " 11  url               14852 non-null  object \n",
      " 12  filename          14852 non-null  object \n",
      "dtypes: float64(3), object(10)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_label</th>\n",
       "      <th>secondary_labels</th>\n",
       "      <th>type</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>scientific_name</th>\n",
       "      <th>common_name</th>\n",
       "      <th>author</th>\n",
       "      <th>license</th>\n",
       "      <th>rating</th>\n",
       "      <th>time</th>\n",
       "      <th>url</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afrsil1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['call', 'flight call']</td>\n",
       "      <td>12.3910</td>\n",
       "      <td>-1.4930</td>\n",
       "      <td>Euodice cantans</td>\n",
       "      <td>African Silverbill</td>\n",
       "      <td>Bram Piot</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>08:00</td>\n",
       "      <td>https://www.xeno-canto.org/125458</td>\n",
       "      <td>afrsil1/XC125458.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afrsil1</td>\n",
       "      <td>['houspa', 'redava', 'zebdov']</td>\n",
       "      <td>['call']</td>\n",
       "      <td>19.8801</td>\n",
       "      <td>-155.7254</td>\n",
       "      <td>Euodice cantans</td>\n",
       "      <td>African Silverbill</td>\n",
       "      <td>Dan Lane</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>08:30</td>\n",
       "      <td>https://www.xeno-canto.org/175522</td>\n",
       "      <td>afrsil1/XC175522.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afrsil1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['call', 'song']</td>\n",
       "      <td>16.2901</td>\n",
       "      <td>-16.0321</td>\n",
       "      <td>Euodice cantans</td>\n",
       "      <td>African Silverbill</td>\n",
       "      <td>Bram Piot</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11:30</td>\n",
       "      <td>https://www.xeno-canto.org/177993</td>\n",
       "      <td>afrsil1/XC177993.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afrsil1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['alarm call', 'call']</td>\n",
       "      <td>17.0922</td>\n",
       "      <td>54.2958</td>\n",
       "      <td>Euodice cantans</td>\n",
       "      <td>African Silverbill</td>\n",
       "      <td>Oscar Campbell</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11:00</td>\n",
       "      <td>https://www.xeno-canto.org/205893</td>\n",
       "      <td>afrsil1/XC205893.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afrsil1</td>\n",
       "      <td>[]</td>\n",
       "      <td>['flight call']</td>\n",
       "      <td>21.4581</td>\n",
       "      <td>-157.7252</td>\n",
       "      <td>Euodice cantans</td>\n",
       "      <td>African Silverbill</td>\n",
       "      <td>Ross Gallardy</td>\n",
       "      <td>Creative Commons Attribution-NonCommercial-Sha...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16:30</td>\n",
       "      <td>https://www.xeno-canto.org/207431</td>\n",
       "      <td>afrsil1/XC207431.ogg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  primary_label                secondary_labels                     type  \\\n",
       "0       afrsil1                              []  ['call', 'flight call']   \n",
       "1       afrsil1  ['houspa', 'redava', 'zebdov']                 ['call']   \n",
       "2       afrsil1                              []         ['call', 'song']   \n",
       "3       afrsil1                              []   ['alarm call', 'call']   \n",
       "4       afrsil1                              []          ['flight call']   \n",
       "\n",
       "   latitude  longitude  scientific_name         common_name          author  \\\n",
       "0   12.3910    -1.4930  Euodice cantans  African Silverbill       Bram Piot   \n",
       "1   19.8801  -155.7254  Euodice cantans  African Silverbill        Dan Lane   \n",
       "2   16.2901   -16.0321  Euodice cantans  African Silverbill       Bram Piot   \n",
       "3   17.0922    54.2958  Euodice cantans  African Silverbill  Oscar Campbell   \n",
       "4   21.4581  -157.7252  Euodice cantans  African Silverbill   Ross Gallardy   \n",
       "\n",
       "                                             license  rating   time  \\\n",
       "0  Creative Commons Attribution-NonCommercial-Sha...     2.5  08:00   \n",
       "1  Creative Commons Attribution-NonCommercial-Sha...     3.5  08:30   \n",
       "2  Creative Commons Attribution-NonCommercial-Sha...     4.0  11:30   \n",
       "3  Creative Commons Attribution-NonCommercial-Sha...     4.0  11:00   \n",
       "4  Creative Commons Attribution-NonCommercial-Sha...     3.0  16:30   \n",
       "\n",
       "                                 url              filename  \n",
       "0  https://www.xeno-canto.org/125458  afrsil1/XC125458.ogg  \n",
       "1  https://www.xeno-canto.org/175522  afrsil1/XC175522.ogg  \n",
       "2  https://www.xeno-canto.org/177993  afrsil1/XC177993.ogg  \n",
       "3  https://www.xeno-canto.org/205893  afrsil1/XC205893.ogg  \n",
       "4  https://www.xeno-canto.org/207431  afrsil1/XC207431.ogg  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.drop(columns=[\"type\", \"latitude\", \"longitude\", \"scientific_name\", \"common_name\", \"license\", \"time\", \"url\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14852 entries, 0 to 14851\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   primary_label     14852 non-null  object \n",
      " 1   secondary_labels  14852 non-null  object \n",
      " 2   author            14852 non-null  object \n",
      " 3   rating            14852 non-null  float64\n",
      " 4   filename          14852 non-null  object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 580.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>primary_label</th>\n",
       "      <th>secondary_labels</th>\n",
       "      <th>author</th>\n",
       "      <th>rating</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>afrsil1</td>\n",
       "      <td>[]</td>\n",
       "      <td>Bram Piot</td>\n",
       "      <td>2.5</td>\n",
       "      <td>afrsil1/XC125458.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>afrsil1</td>\n",
       "      <td>['houspa', 'redava', 'zebdov']</td>\n",
       "      <td>Dan Lane</td>\n",
       "      <td>3.5</td>\n",
       "      <td>afrsil1/XC175522.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afrsil1</td>\n",
       "      <td>[]</td>\n",
       "      <td>Bram Piot</td>\n",
       "      <td>4.0</td>\n",
       "      <td>afrsil1/XC177993.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>afrsil1</td>\n",
       "      <td>[]</td>\n",
       "      <td>Oscar Campbell</td>\n",
       "      <td>4.0</td>\n",
       "      <td>afrsil1/XC205893.ogg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>afrsil1</td>\n",
       "      <td>[]</td>\n",
       "      <td>Ross Gallardy</td>\n",
       "      <td>3.0</td>\n",
       "      <td>afrsil1/XC207431.ogg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  primary_label                secondary_labels          author  rating  \\\n",
       "0       afrsil1                              []       Bram Piot     2.5   \n",
       "1       afrsil1  ['houspa', 'redava', 'zebdov']        Dan Lane     3.5   \n",
       "2       afrsil1                              []       Bram Piot     4.0   \n",
       "3       afrsil1                              []  Oscar Campbell     4.0   \n",
       "4       afrsil1                              []   Ross Gallardy     3.0   \n",
       "\n",
       "               filename  \n",
       "0  afrsil1/XC125458.ogg  \n",
       "1  afrsil1/XC175522.ogg  \n",
       "2  afrsil1/XC177993.ogg  \n",
       "3  afrsil1/XC205893.ogg  \n",
       "4  afrsil1/XC207431.ogg  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 1.2 Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3 entries, 0 to 2\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   row_id    3 non-null      object\n",
      " 1   file_id   3 non-null      object\n",
      " 2   bird      3 non-null      object\n",
      " 3   end_time  3 non-null      int64 \n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 224.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "data_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>file_id</th>\n",
       "      <th>bird</th>\n",
       "      <th>end_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soundscape_1000170626_akiapo_5</td>\n",
       "      <td>soundscape_1000170626</td>\n",
       "      <td>akiapo</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soundscape_1000170626_akiapo_10</td>\n",
       "      <td>soundscape_1000170626</td>\n",
       "      <td>akiapo</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soundscape_1000170626_akiapo_15</td>\n",
       "      <td>soundscape_1000170626</td>\n",
       "      <td>akiapo</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            row_id                file_id    bird  end_time\n",
       "0   soundscape_1000170626_akiapo_5  soundscape_1000170626  akiapo         5\n",
       "1  soundscape_1000170626_akiapo_10  soundscape_1000170626  akiapo        10\n",
       "2  soundscape_1000170626_akiapo_15  soundscape_1000170626  akiapo        15"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## 1.3 Scored birds data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_birds = pd.read_json(\"data/scored_birds.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21 entries, 0 to 20\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   0       21 non-null     object\n",
      "dtypes: object(1)\n",
      "memory usage: 296.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "scored_birds.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>akiapo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aniani</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apapan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>barpet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>crehon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0  akiapo\n",
       "1  aniani\n",
       "2  apapan\n",
       "3  barpet\n",
       "4  crehon"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_birds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 2 Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14852 entries, 0 to 14851\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   primary_label     14852 non-null  object \n",
      " 1   secondary_labels  14852 non-null  object \n",
      " 2   author            14852 non-null  object \n",
      " 3   rating            14852 non-null  float64\n",
      " 4   filename          14852 non-null  object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 580.3+ KB\n"
     ]
    }
   ],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14852.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.719129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.181014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             rating\n",
       "count  14852.000000\n",
       "mean       3.719129\n",
       "std        1.181014\n",
       "min        0.000000\n",
       "25%        3.000000\n",
       "50%        4.000000\n",
       "75%        4.500000\n",
       "max        5.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    3974\n",
       "5.0    3318\n",
       "3.0    1957\n",
       "3.5    1765\n",
       "4.5    1632\n",
       "2.5     724\n",
       "2.0     575\n",
       "0.0     570\n",
       "1.0     155\n",
       "1.5     152\n",
       "0.5      30\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[\"rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train[(data_train[\"rating\"] >= 1.0) & (data_train[\"rating\"] <= 5.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 14252 entries, 0 to 14851\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   primary_label     14252 non-null  object \n",
      " 1   secondary_labels  14252 non-null  object \n",
      " 2   author            14252 non-null  object \n",
      " 3   rating            14252 non-null  float64\n",
      " 4   filename          14252 non-null  object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 668.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    3974\n",
       "5.0    3318\n",
       "3.0    1957\n",
       "3.5    1765\n",
       "4.5    1632\n",
       "2.5     724\n",
       "2.0     575\n",
       "1.0     155\n",
       "1.5     152\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train[\"rating\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data_train[(data_train[\"primary_label\"].isin(scored_birds.iloc[:,0].values)) | (data_train[\"secondary_labels\"].isin(scored_birds.iloc[:,0].values))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1240 entries, 32 to 14762\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   primary_label     1240 non-null   object \n",
      " 1   secondary_labels  1240 non-null   object \n",
      " 2   author            1240 non-null   object \n",
      " 3   rating            1240 non-null   float64\n",
      " 4   filename          1240 non-null   object \n",
      "dtypes: float64(1), object(4)\n",
      "memory usage: 58.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 3 Utilities setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioUtils():\n",
    "    @staticmethod\n",
    "    def open(audio_file):\n",
    "        sig, sr = torchaudio.load(audio_file)\n",
    "        return (sig, sr)\n",
    "\n",
    "    @staticmethod\n",
    "    def rechannel(audio, new_channel):\n",
    "        sig, sr = audio\n",
    "        if sig.shape[0] == new_channel:\n",
    "            return audio\n",
    "        if new_channel == 1:\n",
    "            resig = sig[:1, :]\n",
    "        else:\n",
    "            resig = torch.cat([sig, sig])\n",
    "        return resig, sr\n",
    "\n",
    "    @staticmethod\n",
    "    def resample(audio, newsr):\n",
    "        sig, sr = audio\n",
    "        if sr == newsr:\n",
    "            return audio\n",
    "        num_channels = sig.shape[0]\n",
    "        resig = torchaudio.transforms.Resample(sr, newsr)(sig[:1, :])\n",
    "        if num_channels > 1:\n",
    "            retwo = torchaudio.transforms.Resample(sr, newsr)(sig[1:, :])\n",
    "            resig = torch.cat([resig, retwo])\n",
    "        return resig, newsr\n",
    "\n",
    "    @staticmethod\n",
    "    def pad_trunc(audio, max_ms):\n",
    "        sig, sr = audio\n",
    "        num_rows, sig_len = sig.shape\n",
    "        max_len = sr//1000 * max_ms\n",
    "        if sig_len > max_len:\n",
    "            sig = sig[:, :max_len]\n",
    "        elif sig_len < max_len:\n",
    "            pad_begin_len = random.randint(0, max_len - sig_len)\n",
    "            pad_end_len  =max_len - sig_len - pad_begin_len\n",
    "            pad_begin = torch.zeros((num_rows, pad_begin_len))\n",
    "            pad_end = torch.zeros((num_rows, pad_end_len))\n",
    "            sig = torch.cat((pad_begin, sig, pad_end), 1)\n",
    "        return sig, sr\n",
    "\n",
    "    @staticmethod\n",
    "    def time_shift(audio, shift_limit):\n",
    "        sig, sr = audio\n",
    "        _, sig_len = sig.shape\n",
    "        shift_amt = int(random.random() * shift_limit * sig_len)\n",
    "        return (sig.roll(shift_amt), sr)\n",
    "\n",
    "    @staticmethod\n",
    "    def spectrogram(audio, n_mels=64, n_fft=1024, hop_len=None):\n",
    "        sig, sr = audio\n",
    "        top_db = 80\n",
    "        spec = transforms.MelSpectrogram(sr, n_fft=n_fft, hop_length=hop_len, n_mels=n_mels)(sig)\n",
    "        spec = transforms.AmplitudeToDB(top_db=top_db)(spec)\n",
    "        return spec\n",
    "\n",
    "    def spectrogram_augment(spectrogram, max_mask_pct=0.1, n_freq_maks=1, n_time_masks=1):\n",
    "        _, n_mels, n_steps = spectrogram.shape\n",
    "        mask_value = spectrogram.mean()\n",
    "        aug_spec = spectrogram\n",
    "        freq_mask_param = max_mask_pct * n_mels\n",
    "        for _ in range(n_freq_maks):\n",
    "            aug_spec = transforms.FrequencyMasking(freq_mask_param)(aug_spec, mask_value)\n",
    "        time_mask_param = max_mask_pct * n_steps\n",
    "        for _ in range(n_time_masks):\n",
    "            aug_spec = transforms.TimeMasking(time_mask_param)(aug_spec, mask_value)\n",
    "        return aug_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 4 Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainSoundDataset(Dataset):\n",
    "    def __init__(self, df, data_path, label_encoder):\n",
    "        self.df = df\n",
    "        self.data_path = str(data_path)\n",
    "        self.duration = 4000 # ?\n",
    "        self.sr = 32000\n",
    "        self.channel = 2 # ?\n",
    "        self.shift_pct = 0.4\n",
    "        self.label_encoder = label_encoder\n",
    "        self.df[\"label\"] = self.label_encoder.transform(df[[\"primary_label\"]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        audio_file = self.data_path + self.df[\"filename\"].iloc[index]\n",
    "        label = torch.tensor(self.df[\"label\"].iloc[index], dtype=torch.long)\n",
    "\n",
    "        audio = AudioUtils.open(audio_file)\n",
    "        re_aud = AudioUtils.resample(audio, self.sr)\n",
    "        re_chan = AudioUtils.rechannel(re_aud, self.channel)\n",
    "        dur_aud = AudioUtils.pad_trunc(re_chan, self.duration)\n",
    "        shift_aud = AudioUtils.time_shift(dur_aud, self.shift_pct)\n",
    "        sgram = AudioUtils.spectrogram(shift_aud)\n",
    "        aug_sgram = AudioUtils.spectrogram_augment(sgram)\n",
    "        return aug_sgram, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestSoundDataset(Dataset):\n",
    "    def __init__(self, df, data_path, label_encoder):\n",
    "        self.df = df\n",
    "        self.data_path = str(data_path)\n",
    "        self.duration = 4000 # ?\n",
    "        self.sr = 32000\n",
    "        self.channel = 2 # ?\n",
    "        self.label_encoder = label_encoder\n",
    "        self.df[\"label\"] = self.label_encoder.transform(df[[\"bird\"]])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        audio_file = self.data_path + self.df[\"file_id\"].iloc[index] + \".ogg\"\n",
    "        label = torch.tensor(self.df[\"label\"].iloc[index], dtype=torch.long)\n",
    "\n",
    "        audio = AudioUtils.open(audio_file)\n",
    "        re_aud = AudioUtils.resample(audio, self.sr)\n",
    "        re_chan = AudioUtils.rechannel(re_aud, self.channel)\n",
    "        dur_aud = AudioUtils.pad_trunc(re_chan, self.duration)\n",
    "        sgram = AudioUtils.spectrogram(dur_aud)\n",
    "        return sgram, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrdinalEncoder()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = OrdinalEncoder()\n",
    "label_encoder.fit(data_train[[\"primary_label\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "LABELS_COUNT = scored_birds.value_counts().count()\n",
    "TRAIN_PATH = \"data/train_audio/\"\n",
    "TEST_PATH = \"data/test_soundscapes/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = TrainSoundDataset(data_train, TRAIN_PATH, label_encoder)\n",
    "test_ds = TestSoundDataset(data_test, TEST_PATH, label_encoder)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43048/24595652.py:17: DeprecationWarning: an integer is required (got type numpy.float64).  Implicit conversion to integers using __int__ is deprecated, and may be removed in a future version of Python.\n",
      "  label = torch.tensor(self.df[\"label\"].iloc[index], dtype=torch.long)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[-10.8259,  -6.6460, -11.7051,  ...,  -4.5460, -14.9803,  -3.3526],\n",
       "          [-20.3229, -10.5576, -14.1383,  ...,  -9.3691, -13.6688, -18.8991],\n",
       "          [-18.7182, -16.2491, -20.4181,  ..., -20.2193, -15.4452, -23.3583],\n",
       "          ...,\n",
       "          [-22.1894, -22.1894, -22.1894,  ..., -22.1894, -22.1894, -22.1894],\n",
       "          [-40.0528, -55.3034, -55.3146,  ..., -27.3471, -34.4192, -31.2256],\n",
       "          [-43.0875, -55.3146, -55.3146,  ..., -32.2454, -40.1447, -31.9132]],\n",
       " \n",
       "         [[ -2.1663,  -1.7601, -12.4692,  ...,  -1.4733,  -6.7810, -14.2131],\n",
       "          [-24.6872,  -6.3274, -13.4037,  ...,  -7.0139, -11.5496, -21.6858],\n",
       "          [-22.4923, -12.7291, -19.3943,  ..., -17.3735, -16.0152, -15.2321],\n",
       "          ...,\n",
       "          [-22.1894, -22.1894, -22.1894,  ..., -22.1894, -22.1894, -22.1894],\n",
       "          [-44.1821, -53.0161, -55.3146,  ..., -30.4371, -41.1404, -35.3810],\n",
       "          [-46.2206, -55.3146, -55.3146,  ..., -36.6155, -47.1668, -36.4704]]]),\n",
       " tensor(0))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>file_id</th>\n",
       "      <th>bird</th>\n",
       "      <th>end_time</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>soundscape_1000170626_akiapo_5</td>\n",
       "      <td>soundscape_1000170626</td>\n",
       "      <td>akiapo</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>soundscape_1000170626_akiapo_10</td>\n",
       "      <td>soundscape_1000170626</td>\n",
       "      <td>akiapo</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>soundscape_1000170626_akiapo_15</td>\n",
       "      <td>soundscape_1000170626</td>\n",
       "      <td>akiapo</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            row_id                file_id    bird  end_time  \\\n",
       "0   soundscape_1000170626_akiapo_5  soundscape_1000170626  akiapo         5   \n",
       "1  soundscape_1000170626_akiapo_10  soundscape_1000170626  akiapo        10   \n",
       "2  soundscape_1000170626_akiapo_15  soundscape_1000170626  akiapo        15   \n",
       "\n",
       "   label  \n",
       "0    0.0  \n",
       "1    0.0  \n",
       "2    0.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 5 Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioClassifier(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        conv_layers = []\n",
    "\n",
    "        # CONV BLOCK 1\n",
    "        self.conv_1 = torch.nn.Conv2d(2, 8, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2))\n",
    "        self.relu_1 = torch.nn.ReLU()\n",
    "        self.batchnorm_1 = torch.nn.BatchNorm2d(8)\n",
    "        init.kaiming_normal_(self.conv_1.weight, a=0.1)\n",
    "        self.conv_1.bias.data.zero_()\n",
    "        conv_layers += [self.conv_1, self.relu_1, self.batchnorm_1]\n",
    "\n",
    "        # CONV BLOCK 2\n",
    "        self.conv_2 = torch.nn.Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu_2 = torch.nn.ReLU()\n",
    "        self.batchnorm_2 = torch.nn.BatchNorm2d(16)\n",
    "        init.kaiming_normal_(self.conv_2.weight, a=0.1)\n",
    "        self.conv_2.bias.data.zero_()\n",
    "        conv_layers += [self.conv_2, self.relu_2, self.batchnorm_2]\n",
    "\n",
    "        # CONV BLOCK 3\n",
    "        self.conv_3 = torch.nn.Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu_3 = torch.nn.ReLU()\n",
    "        self.batchnorm_3 = torch.nn.BatchNorm2d(32)\n",
    "        init.kaiming_normal_(self.conv_3.weight, a=0.1)\n",
    "        self.conv_3.bias.data.zero_()\n",
    "        conv_layers += [self.conv_3, self.relu_3, self.batchnorm_3]\n",
    "\n",
    "        # CONV BLOCK 4\n",
    "        self.conv_4 = torch.nn.Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "        self.relu_4 = torch.nn.ReLU()\n",
    "        self.batchnorm_4 = torch.nn.BatchNorm2d(64)\n",
    "        init.kaiming_normal_(self.conv_4.weight, a=0.1)\n",
    "        self.conv_4.bias.data.zero_()\n",
    "        conv_layers += [self.conv_4, self.relu_4, self.batchnorm_4]\n",
    "\n",
    "        self.ap = torch.nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.lin = torch.nn.Linear(in_features=64, out_features=LABELS_COUNT)\n",
    "\n",
    "        self.conv = torch.nn.Sequential(*conv_layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.ap(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.lin(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AudioClassifier()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "next(model.parameters()).device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# 6 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.NLLLoss()\n",
    "torch_scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001,\n",
    "                                            steps_per_epoch=int(len(train_dl)),\n",
    "                                            epochs=NUM_EPOCHS,\n",
    "                                            anneal_strategy='linear')\n",
    "scheduler = LRScheduler(torch_scheduler)\n",
    "\n",
    "val_metrics = {\n",
    "    \"accuracy\": Accuracy(),\n",
    "    \"nll\": Loss(loss_fn)\n",
    "}\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, loss_fn, device=device)\n",
    "evaluator = create_supervised_evaluator(model, metrics=val_metrics, device=device)\n",
    "\n",
    "\n",
    "trainer.add_event_handler(Events.ITERATION_STARTED, scheduler)\n",
    "\n",
    "RunningAverage(output_transform=lambda x: x).attach(trainer, 'loss')\n",
    "ProgressBar(persist=True).attach(trainer, [\"loss\"])\n",
    "\n",
    "# @trainer.on(Events.ITERATION_COMPLETED(every=1))\n",
    "# def log_training_loss(trainer):\n",
    "#     print(f\"Epoch[{trainer.state.epoch}] Loss: {trainer.state.output:.2f}\")\n",
    "\n",
    "# @trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(trainer):\n",
    "    evaluator.run(train_dl)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(f\"Training Resulsts - Epoch: {trainer.state.epoch} Avg accuracy: {metrics['accuracy']:.2f} Av loss: {metrics['nll']:.2f}\")\n",
    "\n",
    "# @trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(test_dl)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(f\"Validation Resulsts - Epoch: {trainer.state.epoch} Avg accuracy: {metrics['accuracy']:.2f} Av loss: {metrics['nll']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.run(train_dl, max_epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.state.output"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d9a8acb4f733d3596df9f6fac9daff15e014d11794ebc65488d1c191c94698fd"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
